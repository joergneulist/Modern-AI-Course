{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ed8c7f",
   "metadata": {
    "id": "60ed8c7f"
   },
   "source": [
    "## Homework 1 - Introduction to Linear Algebra + PyTorch\n",
    "\n",
    "This homework is aimed to familiarize you with some of the basic linear algebra operations we covered in class, as well as how to implement these functions and more in PyTorch.\n",
    "\n",
    "As before, make a copy of the assignment to your drive, add your mugrade key, and then run the cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8934a86a",
   "metadata": {
    "id": "8934a86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/locuslab/mugrade.git\n",
      "  Cloning https://github.com/locuslab/mugrade.git to /tmp/pip-req-build-g7d_w5k6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/locuslab/mugrade.git /tmp/pip-req-build-g7d_w5k6\n",
      "  Resolved https://github.com/locuslab/mugrade.git to commit d79da78488a01d688f7e8d32bef008bfee27af5b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hFile ‘hw1_tests.py’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Run this cell to download and installs the necessary modules for the homework\n",
    "!pip install --upgrade --no-deps git+https://github.com/locuslab/mugrade.git\n",
    "!wget -nc https://raw.githubusercontent.com/modernaicourse/hw1/refs/heads/main/hw1_tests.py\n",
    "\n",
    "import os\n",
    "import mugrade\n",
    "import torch\n",
    "\n",
    "from hw1_tests import images, test_classify_zero_one, submit_classify_zero_one, \\\n",
    "    test_vector_add, submit_vector_add, \\\n",
    "    test_vector_inner_product, submit_vector_inner_product, \\\n",
    "    test_matrix_vector_product_1, submit_matrix_vector_product_1, \\\n",
    "    test_matrix_vector_product_2, submit_matrix_vector_product_2, \\\n",
    "    test_vector_matrix_product_2, submit_vector_matrix_product_2, \\\n",
    "    test_matmul_1, submit_matmul_1, \\\n",
    "    test_matmul_2, submit_matmul_2, \\\n",
    "    test_matmul_3, submit_matmul_3, \\\n",
    "    test_batch_matmul, submit_batch_matmul, \\\n",
    "    test_block_matmul, submit_block_matmul\n",
    "\n",
    "os.environ[\"MUGRADE_HW\"] = \"Homework 1\"\n",
    "#os.environ[\"MUGRADE_KEY\"] = \"\" ### Your key here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a69a0",
   "metadata": {
    "id": "ea4a69a0",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Problem 1: ``Classical'' programming for digit classification\n",
    "\n",
    "This course deals primarily with machine learning approaches, but it's worth emphasizing that you _can_ try to approach many of the problems you'll want to solve with machine learning with traditional programming approaches as well.  In this problem, you should experiment with developing a \"manual\" classifier between images of digits in the MNIST dataset, which will be the first machine learning mode you'll develop during the later assignments.  Specifically, you'll want to implement the following function `classify_zero_one` to classify between images of zeros and ones in the MNIST dataset.  Try to think intuitively about features that might distinguish between zeros and ones, and if possible, try not to look at any statistics from the actual dataset (i.e., average values of the images, or anything like that).\n",
    "\n",
    "You can use the `images` dataset loaded above from the `hw1_tests.py` function (specifically the `images.data` and `images.targets` fields, which have been limited to just include the 0/1 images) to help you develop your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49a5400",
   "metadata": {
    "id": "c49a5400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mugrade: Submitting tests for function classify_zero_one():\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error : {\"detail\":\"Assignment not found for this course\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;129;43m@mugrade\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit_tests\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mclassify_zero_one\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[33;43;03m    Classify a 28x28 pixel image as either a zero or one.\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33;43;03m        integer : 0 or 1\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m### BEGIN YOUR CODE\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/modern-ai-course-eJ7R48Fz-py3.12/lib/python3.12/site-packages/mugrade/mugrade.py:162\u001b[39m, in \u001b[36msubmit_tests\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    160\u001b[39m _values = []\n\u001b[32m    161\u001b[39m _errors = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m _submission_id = \u001b[43mstart_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m test_func(obj)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/modern-ai-course-eJ7R48Fz-py3.12/lib/python3.12/site-packages/mugrade/mugrade.py:57\u001b[39m, in \u001b[36mstart_submission\u001b[39m\u001b[34m(func_name)\u001b[39m\n\u001b[32m     50\u001b[39m response = requests.post(_server_url + \u001b[33m\"\u001b[39m\u001b[33msubmit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m                          params = {\u001b[33m\"\u001b[39m\u001b[33muser_key\u001b[39m\u001b[33m\"\u001b[39m: os.environ[\u001b[33m\"\u001b[39m\u001b[33mMUGRADE_KEY\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     52\u001b[39m                                    \u001b[33m\"\u001b[39m\u001b[33massignment\u001b[39m\u001b[33m\"\u001b[39m: os.environ[\u001b[33m\"\u001b[39m\u001b[33mMUGRADE_HW\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     53\u001b[39m                                    \u001b[33m\"\u001b[39m\u001b[33mproblem\u001b[39m\u001b[33m\"\u001b[39m: func_name},\n\u001b[32m     54\u001b[39m                          verify=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()[\u001b[33m\"\u001b[39m\u001b[33msubmission_id\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mException\u001b[39m: Error : {\"detail\":\"Assignment not found for this course\"}"
     ]
    }
   ],
   "source": [
    "@mugrade.local_tests\n",
    "def classify_zero_one(image):\n",
    "    \"\"\"\n",
    "    Classify a 28x28 pixel image as either a zero or one.\n",
    "\n",
    "    Input:\n",
    "        image : Tensor - 2D tensor storing grayscale pixel values of the image,\n",
    "                         with each element a real-valued number in [0,1]\n",
    "    Output:\n",
    "        integer : 0 or 1\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    def calculate_spread(histogram):\n",
    "        sum_hist = sum(histogram)\n",
    "        avg = sum([i * v for i, v in enumerate(histogram)]) / sum_hist\n",
    "        var = sum([(i - avg)**2 * v for i, v in enumerate(histogram)]) / sum_hist\n",
    "        return var\n",
    "\n",
    "    width = calculate_spread(sum(image).tolist())\n",
    "    height = calculate_spread(sum(image, 1).tolist())\n",
    "    aspect = height / width\n",
    "    classification = int(aspect > 1.5)\n",
    "    return classification\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8af9d",
   "metadata": {
    "id": "30e8af9d"
   },
   "source": [
    "### Problem 2: Vector Addition\n",
    "\n",
    "In the remainder of this assignment, you're going to implement a wide variety of simple linear algebra operators, _without_ using any of the build-in tensor addition or matrix multiplication operators.  Your code should also throw assertion errors if any of the sizes do not match was it allowed for the given operation (i.e., you should be calling assert() to check that the sizes are correct).  Instead, you should use explicit for loops and element-by-element assignment/operations to implement your function.  You can also create new vectors of the right size as your return variable, etc.\n",
    "\n",
    "First implement a simple vector addition function that adds two vectors together, $x,y \\in \\mathbb{R}^n$.  Note that it is ok if this only works when provided with vectors, i.e., 1D tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900bdebc",
   "metadata": {
    "id": "900bdebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mugrade: Submitting tests for function vector_add():\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error : {\"detail\":\"Assignment not found for this course\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;129;43m@mugrade\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit_tests\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mvector_add\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[33;43;03m    Add two vectors x and y, _without_ using the built-in addition of torch.\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[33;43;03m    Instead, you need to manually iterate through the elements of x and y and\u001b[39;49;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m### BEGIN YOUR CODE\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/modern-ai-course-eJ7R48Fz-py3.12/lib/python3.12/site-packages/mugrade/mugrade.py:162\u001b[39m, in \u001b[36msubmit_tests\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    160\u001b[39m _values = []\n\u001b[32m    161\u001b[39m _errors = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m _submission_id = \u001b[43mstart_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m test_func(obj)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/modern-ai-course-eJ7R48Fz-py3.12/lib/python3.12/site-packages/mugrade/mugrade.py:57\u001b[39m, in \u001b[36mstart_submission\u001b[39m\u001b[34m(func_name)\u001b[39m\n\u001b[32m     50\u001b[39m response = requests.post(_server_url + \u001b[33m\"\u001b[39m\u001b[33msubmit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m                          params = {\u001b[33m\"\u001b[39m\u001b[33muser_key\u001b[39m\u001b[33m\"\u001b[39m: os.environ[\u001b[33m\"\u001b[39m\u001b[33mMUGRADE_KEY\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     52\u001b[39m                                    \u001b[33m\"\u001b[39m\u001b[33massignment\u001b[39m\u001b[33m\"\u001b[39m: os.environ[\u001b[33m\"\u001b[39m\u001b[33mMUGRADE_HW\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     53\u001b[39m                                    \u001b[33m\"\u001b[39m\u001b[33mproblem\u001b[39m\u001b[33m\"\u001b[39m: func_name},\n\u001b[32m     54\u001b[39m                          verify=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()[\u001b[33m\"\u001b[39m\u001b[33msubmission_id\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mException\u001b[39m: Error : {\"detail\":\"Assignment not found for this course\"}"
     ]
    }
   ],
   "source": [
    "@mugrade.local_tests\n",
    "def vector_add(x,y):\n",
    "    \"\"\"\n",
    "    Add two vectors x and y, _without_ using the built-in addition of torch.\n",
    "    Instead, you need to manually iterate through the elements of x and y and\n",
    "    add them together.  The function should throw an AssertionError, via\n",
    "    calling assert(), if the vectors are not the proper size to add together.\n",
    "\n",
    "    Input:\n",
    "        x : 1D torch.Tensor - first term to add\n",
    "        y : 1D torch.Tensor - second term to add\n",
    "\n",
    "    Output:\n",
    "        return 1D torch.Tensor - sum of x + y\n",
    "\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert x.shape == y.shape\n",
    "    assert len(x.shape) == 1\n",
    "    return torch.Tensor([a + b for a, b in zip(x.tolist(), y.tolist())])\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6bbbc1",
   "metadata": {
    "id": "af6bbbc1"
   },
   "source": [
    "### Problem 3: Vector inner product\n",
    "\n",
    "Now implement the vector inner product.  I.e., for two vectors $x, y \\in \\mathbb{R}^n$, return the inner product\n",
    "$$\\langle x,y \\rangle \\equiv x^T y = \\sum_{i=1}^n x_i y_i.$$\n",
    "\n",
    "As before, don't use any PyTorch functions that compute a matrix multiplication or inner product directly, but do it all with for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b95df1",
   "metadata": {
    "id": "06b95df1"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def vector_inner_product(x,y):\n",
    "    \"\"\"\n",
    "    Compute the inner product between two vectors x and y, _without_ using the\n",
    "    matrix multiplication operator '@' (or any similar PyTorch function). The\n",
    "    function should throw an AssertionError if the vectors are not the proper\n",
    "    size.\n",
    "\n",
    "    Input:\n",
    "        x : 1D torch.Tensor - first term to add\n",
    "        y : 1D torch.Tensor - second term to add\n",
    "\n",
    "    Output:\n",
    "        return float - inner product <x,y>\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert x.shape == y.shape\n",
    "    assert len(x.shape) == 1\n",
    "    result = sum([a * b for a, b in zip(x.tolist(), y.tolist())])\n",
    "    return result\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682888f6",
   "metadata": {
    "id": "682888f6"
   },
   "source": [
    "### Problem 4: Matrix-vector product approach #1\n",
    "\n",
    "Write a routine that function that computes the matrix-vector product $Ax$ for $A \\in \\mathbb{R}^{m \\times n}$ and $x \\in \\mathbb{R}^n$.  This version should compute each entry of the resuting vector using the inner product between rows of $A$ and the vector $x$, i.e., shown graphically this would be\n",
    "$$\n",
    "Ax = \\left [ \\begin{array}{ccc}\n",
    "\\;\\text{—} & a^T_1 & \\text{—}\\; \\\\\n",
    "\\;\\text{—} & a^T_2 & \\text{—}\\; \\\\\n",
    "& \\vdots & \\\\\n",
    "\\;\\text{—} & a^T_m & \\text{—}\\;\n",
    "\\end{array} \\right ] \\left [ \\begin{array}{c}\\mid \\\\ x \\\\ \\mid \\end{array}  \\right ] = \\left [ \\begin{array}{c} a^T_1 x \\\\ a^T_2 x \\\\ \\vdots \\\\ a^T_m x \\end{array} \\right].\n",
    "$$\n",
    "\n",
    "Only make use of the above-implemented `vector_inner_product()` function you implemetned above for this routine, i.e., no other operations on the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53e02f",
   "metadata": {
    "id": "eb53e02f"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def matrix_vector_product_1(A,x):\n",
    "    \"\"\"\n",
    "    Compute the matrix vector product Ax _without_ using the matrix\n",
    "    multiplication operator @ or any related function.  In this variant\n",
    "    implement the output as the inner product of each row of A with\n",
    "    the vector x (i.e., only make use of the vector_inner_product function).\n",
    "    Be sure to throw AssertionErrors if the product is not valid.\n",
    "\n",
    "    Input:\n",
    "        A : 2D torch.Tensor - m x n matrix A\n",
    "        x : 1D torch.Tensor - vector x with n elements\n",
    "\n",
    "    Output:\n",
    "        return 1D torch.Tensor - vector Ax with m elements\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(x.shape) == 1    \n",
    "    assert A.shape[1] == x.shape[0]\n",
    "    return torch.Tensor([vector_inner_product(y, x) for y in A])\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748084fb",
   "metadata": {
    "id": "748084fb"
   },
   "source": [
    "### Problem 5: Matrix-vector product approach #2\n",
    "\n",
    "Write a routine that function that computes the matrix-vector product $Ax$ for $A \\in \\mathbb{R}^{m \\times n}$ and $x \\in \\mathbb{R}^n$.  This version should compute the result as a linear combination of the columns of $A$ with coefficients given by the entries of $x_i$, i.e., shows graphically this would be\n",
    "$$\n",
    "Ax = \\left [ \\begin{array}{cccc} \\mid & \\mid & & \\mid \\\\\n",
    "a_1 & a_2 & \\cdots & a_n \\\\\n",
    "\\mid & \\mid & & \\mid \\end{array} \\right ]\n",
    "\\left [ \\begin{array}{c} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{array}\\right ] =\n",
    "\\left [ \\begin{array}{c} \\mid \\\\ a_1 \\\\ \\mid \\end{array} \\right ] x_1 +\n",
    "\\left [ \\begin{array}{c} \\mid \\\\ a_2 \\\\ \\mid \\end{array} \\right ] x_2 + \\ldots +\n",
    "\\left [ \\begin{array}{c} \\mid \\\\ a_n \\\\ \\mid \\end{array} \\right ] x_n\n",
    "$$\n",
    "\n",
    "Only make use of the above-implemented `vector_add()` function to implement your solution (plus of course creating vectors to return, etc).  It is also ok to multiply a vector by a scalar, i.e., the code `c*y` where `c` is a vector and `y` is a real-valued scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e2139",
   "metadata": {
    "id": "c67e2139"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def matrix_vector_product_2(A,x):\n",
    "    \"\"\"\n",
    "    Compute the matrix vector product Ax _without_ using the matrix\n",
    "    multiplication operator @ or any related function.  In this variant\n",
    "    implement the output as a linear combination of the columns of A with\n",
    "    coefficients given by the entries of x (and only make use of the\n",
    "    vector_add function).  Be sure to throw AssertionErrors if the sizes do\n",
    "    not allow for a valid product\n",
    "\n",
    "    Input:\n",
    "        A : 2D torch.Tensor - m x n matrix A\n",
    "        x : 1D torch.Tensor - vector x with n elements\n",
    "\n",
    "    Output:\n",
    "        return 1D torch.Tensor - vector Ax with m elements\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(x.shape) == 1    \n",
    "    assert A.shape[1] == x.shape[0]\n",
    "    result = torch.Tensor().new_zeros(size=[A.shape[0]])\n",
    "    for v, s in zip(A.t(), x):\n",
    "        result = vector_add(result, v * s)\n",
    "    return result\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f8be0",
   "metadata": {
    "id": "9c7f8be0"
   },
   "source": [
    "### Problem 6: Vector-matrix product approach #2\n",
    "\n",
    "Write a routine that function that computes the vector-Matrix product $x^TA$ for $A \\in \\mathbb{R}^{m \\times n}$ and $x \\in \\mathbb{R}^m$.  In keeping with PyTorch convention (i.e., not differentiating between column and row vectors), this should return a 1D tensor representing the resulting row vector.  \n",
    "\n",
    "This version should compute the result as a linear combination of the rows of $A$ with coefficients given by the entries of $x_i$, i.e., shows graphically this would be\n",
    "$$\n",
    "\\begin{split}\n",
    "x^T A & =\n",
    "\\left [ \\begin{array}{cccc} x_1 & x_2 & \\ldots & x_m \\end{array} \\right ]\n",
    "\n",
    "\\left [ \\begin{array}{ccc}\n",
    "\\;\\text{—} & a^T_1 & \\text{—}\\; \\\\\n",
    "\\;\\text{—} & a^T_2 & \\text{—}\\; \\\\\n",
    "& \\vdots & \\\\\n",
    "\\;\\text{—} & a^T_m & \\text{—}\\;\n",
    "\\end{array} \\right ] \\\\ & =\n",
    "\n",
    "x_1 \\left [ \\begin{array}{ccc} \\;\\text{—} & a^T_1 & \\text{—}\\; \\end{array} \\right ] +\n",
    "x_2 \\left [ \\begin{array}{ccc} \\;\\text{—} & a^T_2 & \\text{—}\\; \\end{array} \\right ] + \\ldots +\n",
    "x_m \\left [ \\begin{array}{ccc} \\;\\text{—} & a^T_m & \\text{—}\\; \\end{array} \\right ]\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Only make use of the above-implemented `vector_add()` function to implement your solution, with the same caveats as in the previous problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10257dd9",
   "metadata": {
    "id": "10257dd9"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def vector_matrix_product_2(x,A):\n",
    "    \"\"\"\n",
    "    Compute the vector Matrix product x^T A _without_ using the matrix\n",
    "    multiplication operator @ or any related function.  In this variant\n",
    "    implement the output as a linear combination of the rows of A with\n",
    "    coefficients given by the entries of x (and only make use of the\n",
    "    vector_add function).  Note that, in keeping with PyTorch convention (of\n",
    "    not differentiating between row and column vectors), x will just be an\n",
    "    vector (1D tensor) with m elements, and the output should be a vector (1D\n",
    "    Tensor) with n elements. Be sure to throw AssertionErrors if the sizes do\n",
    "    not allow for a valid product.\n",
    "\n",
    "    Input:\n",
    "        A : 2D torch.Tensor - m x n matrix A\n",
    "        x : 1D torch.Tensor - vector x with m elements\n",
    "\n",
    "    Output:\n",
    "        return 1D torch.Tensor - vector x^T A with n elements\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(x.shape) == 1    \n",
    "    assert A.shape[0] == x.shape[0]\n",
    "    result = torch.Tensor().new_zeros(size=[A.shape[1]])\n",
    "    for v, s in zip(A, x):\n",
    "        result = vector_add(result, v * s)\n",
    "    return result\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788d725",
   "metadata": {
    "id": "4788d725"
   },
   "source": [
    "### Problem 7: Matrix-matrix multiplication approach #1\n",
    "\n",
    "Write a matrix-matrix multiplication function, again without using any built-in operators.  For $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{m \\times p}$, this version should compute each element $(AB)_{ij}$ as the inner product of the $i$th row of $A$ and the $j$th column of $B$.  Depicted graphically, this would be the breakdown\n",
    "$$\n",
    "AB =\n",
    "\\left [ \\begin{array}{ccc}\n",
    "\\;\\text{—} & a^T_1 & \\text{—}\\; \\\\\n",
    "\\;\\text{—} & a^T_2 & \\text{—}\\; \\\\\n",
    "& \\vdots & \\\\\n",
    "\\;\\text{—} & a^T_m & \\text{—}\\;\n",
    "\\end{array} \\right ]\n",
    "\n",
    "\\left [ \\begin{array}{cccc} \\mid & \\mid & & \\mid \\\\\n",
    "b_1 & b_2 & \\cdots & b_p \\\\\n",
    "\\mid & \\mid & & \\mid \\end{array} \\right ]\n",
    "=\n",
    "\\left [ \\begin{array}{cccc} a_1^T b_1 & a_1^T b_2 & \\cdots & a_1^T b_p \\\\\n",
    "a_2^T b_1 & a_1^T b_2 & \\cdots & a_2^T b_p \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_m^T b_1 & a_m^T b_2 & \\cdots & a_m^T b_p \\end{array} \\right ]\n",
    "$$\n",
    "\n",
    "With all the same caveats as before, this implementation should only use the function `vector_inner_product()` that you implemented above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29c8e7",
   "metadata": {
    "id": "3a29c8e7"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def matmul_1(A,B):\n",
    "    \"\"\"\n",
    "    Compute the matrix matrix multiplication AB without using the @ operator.\n",
    "    In this variant, compute each entry of the matrix product as the inner\n",
    "    product of a row of A and a column of B (i.e., using the\n",
    "    vector_inner_product function).  Be sure to throw AssertionErrors if the\n",
    "    sizes of the matrices do not make for a valid product.\n",
    "\n",
    "\n",
    "    Input:\n",
    "        A : 2D torch.Tensor - m x n matrix A\n",
    "        B : 2D torch.Tensor - n x p matrix B\n",
    "\n",
    "    Output:\n",
    "        return 2D torch.Tensor - m x p matrix equal to the product AB\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(B.shape) == 2\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    result = torch.Tensor([\n",
    "        [vector_inner_product(vA, vB) for vB in B.t()]\n",
    "        for vA in A])\n",
    "    return result\n",
    "    ### END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79331d",
   "metadata": {
    "id": "9a79331d"
   },
   "source": [
    "### Problem 8: Matrix-matrix multiplication approach #2\n",
    "\n",
    "Write another matrix multiplication implemention. For $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{m \\times p}$, this version should compute the $i$th column of $AB$ as the matrix-vector product between $A$ and $i$th column of $B$. Depicted graphically, this would be the breakdown\n",
    "$$\n",
    "AB =\n",
    "A\n",
    "\\left [ \\begin{array}{cccc} \\mid & \\mid & & \\mid \\\\\n",
    "b_1 & b_2 & \\cdots & b_p \\\\\n",
    "\\mid & \\mid & & \\mid \\end{array} \\right ]\n",
    "=\n",
    "\\left [ \\begin{array}{cccc} \\mid & \\mid & & \\mid \\\\\n",
    "A b_1 & A b_2 & \\cdots & A b_p \\\\\n",
    "\\mid & \\mid & & \\mid \\end{array} \\right ]\n",
    "$$\n",
    "\n",
    "With all the same caveats as before, this implementation should only use the function `matrix_vector_product_1()` (or `matrix_vector_product_2()`) that you implemented above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a324d3",
   "metadata": {
    "id": "94a324d3"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def matmul_2(A,B):\n",
    "    \"\"\"\n",
    "    Compute the matrix matrix multiplication AB without using the @ operator.\n",
    "    In this variant, compute the ith _column_ of the matrix product as the\n",
    "    matrix-vector product of A and the ith column of B (i.e., using only the\n",
    "    function matrix_vector_product_1 or matrix_vector_product_2). Be sure to\n",
    "    throw AssertionErrors if the sizes of the matrices do not make for a valid\n",
    "    product.\n",
    "\n",
    "    Input:\n",
    "        A : 2D torch.Tensor - m x n matrix A\n",
    "        B : 2D torch.Tensor - n x p matrix B\n",
    "\n",
    "    Output:\n",
    "        return 2D torch.Tensor - m x p matrix equal to the product AB\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(B.shape) == 2\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    result = torch.stack([\n",
    "        matrix_vector_product_1(A, vB)\n",
    "        for vB in B.t()])\n",
    "    return result.t()\n",
    "    ### END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75eb6c",
   "metadata": {
    "id": "fc75eb6c"
   },
   "source": [
    "### Problem 9: Matrix-matrix multiplication approach #3\n",
    "\n",
    "Finally, write one last matrix multiplication implementation. For $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{m \\times p}$, this version should compute the $i$th row of $AB$ as the vector-matrix product between the $i$th row of $A$ and $B$. This would be the breakdown\n",
    "$$\n",
    "AB =\n",
    "\\left [ \\begin{array}{ccc}\n",
    "\\;\\text{—} & a^T_1 & \\text{—}\\; \\\\\n",
    "\\;\\text{—} & a^T_2 & \\text{—}\\; \\\\\n",
    "& \\vdots & \\\\\n",
    "\\;\\text{—} & a^T_m & \\text{—}\\;\n",
    "\\end{array} \\right ] B =\n",
    "\\left [ \\begin{array}{ccc}\n",
    "\\;\\text{—} & a^T_1 B & \\text{—}\\; \\\\\n",
    "\\;\\text{—} & a^T_2 B & \\text{—}\\; \\\\\n",
    "& \\vdots & \\\\\n",
    "\\;\\text{—} & a^T_m B & \\text{—}\\;\n",
    "\\end{array} \\right ]\n",
    "$$\n",
    "\n",
    "\n",
    "With all the same caveats as before, this implementation should only use the function `vector_matrix_product_2()` that you implemented above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89ddc9",
   "metadata": {
    "id": "6c89ddc9"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def matmul_3(A,B):\n",
    "    \"\"\"\n",
    "    Compute the matrix matrix multiplication AB without using the @ operator.\n",
    "    In this variant, compute the ith _row_ of the matrix product as the\n",
    "    vector-matrix product of the ith row A and B (i.e., using only the\n",
    "    function vector_matrix_product_2). Be sure to throw AssertionErrors if the\n",
    "    sizes of the matrices do not make for a valid product.\n",
    "\n",
    "    Input:\n",
    "        A : 2D torch.Tensor - m x n matrix A\n",
    "        B : 2D torch.Tensor - n x p matrix B\n",
    "\n",
    "    Output:\n",
    "        return 2D torch.Tensor - m x p matrix equal to the product AB\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(B.shape) == 2\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    result = torch.stack([\n",
    "        vector_matrix_product_2(vA, B)\n",
    "        for vA in A])\n",
    "    return result\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1139fd",
   "metadata": {
    "id": "6b1139fd"
   },
   "source": [
    "### Problem 10: Batch matrix multiplication\n",
    "\n",
    "In this problem, you will implement batch matrix multiplication.  Consider two ND PyTorch tensors of the dimensions $A \\in \\mathbb{R}^{n_1 \\times n_2 \\times \\ldots \\times n_d}$ $B \\in \\mathbb{R}^{m_1 \\times m_2 \\times \\ldots \\times m_d}$ with the same sizes on all but the last two dimensions\n",
    "$$ n_i = m_i, \\; i=1,\\ldots,d-2$$\n",
    "and the last two dimensions properly sized for a matrix multiplication\n",
    "$$n_i = m_{i-1}.$$\n",
    "In this case implement a batched version of matrix multiplication that iterates over all the leading $d-2$ dimensions and performs a matrix multiplication of the corresponding entries.  The function should throw an AssertionError if any of the sizes do not match.\n",
    "\n",
    "You should still not use the PyTorch matrix multiplication operator, but instead call one of the `matmul()` functions you implemented above (it doesn't really matter which one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4abb76",
   "metadata": {
    "id": "ed4abb76"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def batch_matmul(A,B):\n",
    "    \"\"\"\n",
    "    Implement batch matrix multiplication between 2 tensors A and B by\n",
    "    iterating over all the leading dimensions of A and B (all dimensions other\n",
    "    than the last two), and performing a matrix multiplication over the last\n",
    "    two dimensions. A and B must be sized so that their leading dimensions are\n",
    "    all the same, and the last two dimensions are sized for a valid matrix\n",
    "    multiplication.\n",
    "\n",
    "    Inputs:\n",
    "        A : torch.Tensor - ND tensor with trailing dimensions (..., m, n)\n",
    "        B : torch.Tensor - ND tensor with trailing dimensions (..., n, p)\n",
    "\n",
    "    Output:\n",
    "        return torch.Tensor - ND tensor with tailing dimensions (..., m, p)\n",
    "                              containing all matrix multiplications of the\n",
    "                              corresponding entries.\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == len(B.shape)\n",
    "    if len(A.shape) == 2:\n",
    "        return matmul_3(A, B)\n",
    "    else:\n",
    "        assert A.shape[0] == B.shape[0]\n",
    "        return torch.stack([batch_matmul(*reduced) for reduced in zip(A, B)])\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b998e7d",
   "metadata": {
    "id": "4b998e7d"
   },
   "source": [
    "### Problem 11: Block matrix multiplication\n",
    "In this last question, you'll implement a \"blocked\" form of matrix multiplication.  Although we defined matrix multiplication in terms of the individual scalar entries of a matrix, it can also be defined by operating on subblocks of the matrices.  Specifically for an matrix $A \\in \\mathbb{R}^{4m \\times 4n}$ we can define $A_{ij} \\in \\mathbb{R}^{4 \\times 4}$ to be a _subblock_ of the matrix, and similarly for the matrix $B \\in \\mathbb{R}^{4n \\times 4p}.  Then the corresponding $4 \\times 4$ subblock of the matrix product $AB$ can be computed as\n",
    "$$ (AB)_ij = \\sum_{k=1}^n A_{ik} B_{kj} $$\n",
    "analogous to the usual definition of matrix multiplication, but with $A_{ik} B_{kj}$ now being a matrix product.\n",
    "\n",
    "In practice, techniques like this (with proper memory layouts, which we don't cover here) are how write fast matrix multiplication primitives on GPUs (where e.g., so-called \"tensor cores\" actually exactly perform 4x4 matrix multiplication).\n",
    "\n",
    "Implement the `block_matmul` function below.  You should _only_ call the `add_matmul_44()` function in your implementation.  You should check to ensure that the matrices form a valid matrix multiplication, and that they are all divisible by 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8b83a",
   "metadata": {
    "id": "b1f8b83a"
   },
   "outputs": [],
   "source": [
    "def add_matmul_44(Z,A,B):\n",
    "    \"\"\"\n",
    "    Simulate a \"fast\" 4x4 matrix multiplication and in-place addition to Z:\n",
    "        Z += AB\n",
    "    \"\"\"\n",
    "    assert(Z.shape == (4,4) and A.shape == (4,4) and B.shape == (4,4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            Z[i,j] += A[i,0]*B[0,j] + A[i,1]*B[1,j] + A[i,2]*B[2,j] + A[i,3]*B[3,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03592d75",
   "metadata": {
    "id": "03592d75"
   },
   "outputs": [],
   "source": [
    "@mugrade.local_tests\n",
    "def block_matmul(A,B):\n",
    "    \"\"\"\n",
    "    Implement a block matrix multiplication to compute the matrix-matrix\n",
    "    product AB.  You should use the formula above, and also assert that that\n",
    "    matrices are the proper shapes (and have dimensions that are multiples of\n",
    "    4).  Use only the matmul_44 call.\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    assert len(A.shape) == 2\n",
    "    assert len(B.shape) == 2\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    assert A.shape[0] % 4 == 0\n",
    "    assert A.shape[1] % 4 == 0\n",
    "    assert B.shape[1] % 4 == 0\n",
    "    n4 = A.shape[1]\n",
    "    def calc_submatrix(i, j):\n",
    "        result = torch.Tensor().new_zeros(size=(4, 4))\n",
    "        for k in range(0, n4, 4):\n",
    "            add_matmul_44(result, A[i:i+4,k:k+4], B[k:k+4,j:j+4])\n",
    "        return result\n",
    "\n",
    "    return torch.cat([\n",
    "        torch.cat([calc_submatrix(i, j) for i in range(0, A.shape[0], 4)], axis=0)\n",
    "        for j in range(0, B.shape[1], 4)],\n",
    "        axis=1)\n",
    "    ### END YOUR CODE\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
